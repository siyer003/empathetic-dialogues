{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938ace9d",
   "metadata": {},
   "source": [
    "### Model 2: BART-Base Chatbot with RoBERTa Emotion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e544deb-db5a-4c7e-b168-22ebf3608828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33c9c7b-ed1f-4bbf-97ae-9904cbf9eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c150db21-d113-4675-8e8f-f09800d23194",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('facebook/empathetic_dialogues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d96559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"empathetic_dialogues\")\n",
    "train_dataset = Dataset.from_file(\"./empathetic_dialogues-train.arrow\")\n",
    "\n",
    "val_dataset = Dataset.from_file(\"./empathetic_dialogues-validation.arrow\")\n",
    "\n",
    "test_dataset = Dataset.from_file(\"./empathetic_dialogues-test.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a942e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e68b8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags'],\n",
       "    num_rows: 76673\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b100f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_id': ['hit:0_conv:1',\n",
       "  'hit:0_conv:1',\n",
       "  'hit:0_conv:1',\n",
       "  'hit:0_conv:1',\n",
       "  'hit:0_conv:1'],\n",
       " 'utterance_idx': [1, 2, 3, 4, 5],\n",
       " 'context': ['sentimental',\n",
       "  'sentimental',\n",
       "  'sentimental',\n",
       "  'sentimental',\n",
       "  'sentimental'],\n",
       " 'prompt': ['I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.',\n",
       "  'I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.',\n",
       "  'I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.',\n",
       "  'I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.',\n",
       "  'I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.'],\n",
       " 'speaker_idx': [1, 0, 1, 0, 1],\n",
       " 'utterance': ['I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people_comma_ we felt like the only people in the world.',\n",
       "  'Was this a friend you were in love with_comma_ or just a best friend?',\n",
       "  'This was a best friend. I miss her.',\n",
       "  'Where has she gone?',\n",
       "  'We no longer talk.'],\n",
       " 'selfeval': ['5|5|5_2|2|5',\n",
       "  '5|5|5_2|2|5',\n",
       "  '5|5|5_2|2|5',\n",
       "  '5|5|5_2|2|5',\n",
       "  '5|5|5_2|2|5'],\n",
       " 'tags': ['', '', '', '', '']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0799f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_empathetic_dataset(dataset_split, max_turns=3):\n",
    "    import pandas as pd\n",
    "\n",
    "    def clean_text(text):\n",
    "        return text.replace('_comma_', ',').replace('_period_', '.').replace('_exclamation_', '!').strip()\n",
    "\n",
    "    df = pd.DataFrame(dataset_split)\n",
    "    df = df.sort_values(by=['conv_id', 'utterance_idx']).reset_index(drop=True)\n",
    "\n",
    "    pairs = []\n",
    "    for conv_id, conv in df.groupby('conv_id'):\n",
    "        history = []\n",
    "        for _, row in conv.iterrows():\n",
    "            utterance = clean_text(row['utterance'])\n",
    "            emotion = row['context']\n",
    "            speaker = row['speaker_idx']\n",
    "\n",
    "            if history:\n",
    "                truncated_history = history[-max_turns:]\n",
    "                history_str = \" \".join(truncated_history)\n",
    "                input_text = f\"<emotion={emotion}> {history_str}\"\n",
    "                pairs.append({\n",
    "                    \"input_bart\": input_text,\n",
    "                    \"response\": utterance,\n",
    "                    \"emotion\": emotion\n",
    "                })\n",
    "            history.append(f\"[Speaker {speaker}] {utterance}\")\n",
    "\n",
    "    return Dataset.from_pandas(pd.DataFrame(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying to each split\n",
    "dataset_processed = DatasetDict({\n",
    "    \"train\": process_empathetic_dataset(dataset['train']),\n",
    "    \"validation\": process_empathetic_dataset(dataset['validation']),\n",
    "    \"test\": process_empathetic_dataset(dataset['test'])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d62d14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_bart': '<emotion=sentimental> [Speaker 1] I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people, we felt like the only people in the world. [Speaker 0] Was this a friend you were in love with, or just a best friend?',\n",
       " 'response': 'This was a best friend. I miss her.',\n",
       " 'emotion': 'sentimental'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_processed['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcff326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b90a9c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50297, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "# Add emotion tokens\n",
    "emotions = list(set(dataset_processed[\"train\"][\"emotion\"]))\n",
    "special_tokens = [f\"<emotion={e}>\" for e in emotions]\n",
    "tokenizer.add_tokens(special_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the dataset\n",
    "def tokenize_fn(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"input_bart\"],\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            example[\"response\"],\n",
    "            max_length=64,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0e3db8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d4bf07caba4e608326a48c514aa475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58829 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd48f50296f845fe8ea1735511dbd1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d955de040703487f8f17a1d7c7beac50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset_processed.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42006d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_bart': '<emotion=sentimental> [Speaker 1] I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people, we felt like the only people in the world.',\n",
       " 'response': 'Was this a friend you were in love with, or just a best friend?',\n",
       " 'emotion': 'sentimental',\n",
       " 'input_ids': [0,\n",
       "  50283,\n",
       "  10975,\n",
       "  29235,\n",
       "  4218,\n",
       "  112,\n",
       "  742,\n",
       "  38,\n",
       "  2145,\n",
       "  164,\n",
       "  7,\n",
       "  192,\n",
       "  5,\n",
       "  10756,\n",
       "  19,\n",
       "  127,\n",
       "  275,\n",
       "  1441,\n",
       "  4,\n",
       "  85,\n",
       "  21,\n",
       "  5,\n",
       "  78,\n",
       "  86,\n",
       "  52,\n",
       "  655,\n",
       "  1240,\n",
       "  86,\n",
       "  1937,\n",
       "  561,\n",
       "  4,\n",
       "  2223,\n",
       "  89,\n",
       "  21,\n",
       "  10,\n",
       "  319,\n",
       "  9,\n",
       "  82,\n",
       "  6,\n",
       "  52,\n",
       "  1299,\n",
       "  101,\n",
       "  5,\n",
       "  129,\n",
       "  82,\n",
       "  11,\n",
       "  5,\n",
       "  232,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [0,\n",
       "  32112,\n",
       "  42,\n",
       "  10,\n",
       "  1441,\n",
       "  47,\n",
       "  58,\n",
       "  11,\n",
       "  657,\n",
       "  19,\n",
       "  6,\n",
       "  50,\n",
       "  95,\n",
       "  10,\n",
       "  275,\n",
       "  1441,\n",
       "  116,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a39c18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_bart', 'response', 'emotion', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 58829\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_bart', 'response', 'emotion', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9267\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_bart', 'response', 'emotion', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8401\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d44d6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\"input_bart\", \"response\", \"emotion\"]\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27e60732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0,\n",
       "  50283,\n",
       "  10975,\n",
       "  29235,\n",
       "  4218,\n",
       "  112,\n",
       "  742,\n",
       "  38,\n",
       "  2145,\n",
       "  164,\n",
       "  7,\n",
       "  192,\n",
       "  5,\n",
       "  10756,\n",
       "  19,\n",
       "  127,\n",
       "  275,\n",
       "  1441,\n",
       "  4,\n",
       "  85,\n",
       "  21,\n",
       "  5,\n",
       "  78,\n",
       "  86,\n",
       "  52,\n",
       "  655,\n",
       "  1240,\n",
       "  86,\n",
       "  1937,\n",
       "  561,\n",
       "  4,\n",
       "  2223,\n",
       "  89,\n",
       "  21,\n",
       "  10,\n",
       "  319,\n",
       "  9,\n",
       "  82,\n",
       "  6,\n",
       "  52,\n",
       "  1299,\n",
       "  101,\n",
       "  5,\n",
       "  129,\n",
       "  82,\n",
       "  11,\n",
       "  5,\n",
       "  232,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [0,\n",
       "  32112,\n",
       "  42,\n",
       "  10,\n",
       "  1441,\n",
       "  47,\n",
       "  58,\n",
       "  11,\n",
       "  657,\n",
       "  19,\n",
       "  6,\n",
       "  50,\n",
       "  95,\n",
       "  10,\n",
       "  275,\n",
       "  1441,\n",
       "  116,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "886ace1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d95619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./bart_empathetic\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2495a9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/transformers/4.21.1/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 58829\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22062\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22062' max='22062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22062/22062 20:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.834700</td>\n",
       "      <td>0.791759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.699400</td>\n",
       "      <td>0.778504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.773866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9267\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./bart_empathetic/checkpoint-7354\n",
      "Configuration saved in ./bart_empathetic/checkpoint-7354/config.json\n",
      "Model weights saved in ./bart_empathetic/checkpoint-7354/pytorch_model.bin\n",
      "tokenizer config file saved in ./bart_empathetic/checkpoint-7354/tokenizer_config.json\n",
      "Special tokens file saved in ./bart_empathetic/checkpoint-7354/special_tokens_map.json\n",
      "added tokens file saved in ./bart_empathetic/checkpoint-7354/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9267\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./bart_empathetic/checkpoint-14708\n",
      "Configuration saved in ./bart_empathetic/checkpoint-14708/config.json\n",
      "Model weights saved in ./bart_empathetic/checkpoint-14708/pytorch_model.bin\n",
      "tokenizer config file saved in ./bart_empathetic/checkpoint-14708/tokenizer_config.json\n",
      "Special tokens file saved in ./bart_empathetic/checkpoint-14708/special_tokens_map.json\n",
      "added tokens file saved in ./bart_empathetic/checkpoint-14708/added_tokens.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9267\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./bart_empathetic/checkpoint-22062\n",
      "Configuration saved in ./bart_empathetic/checkpoint-22062/config.json\n",
      "Model weights saved in ./bart_empathetic/checkpoint-22062/pytorch_model.bin\n",
      "tokenizer config file saved in ./bart_empathetic/checkpoint-22062/tokenizer_config.json\n",
      "Special tokens file saved in ./bart_empathetic/checkpoint-22062/special_tokens_map.json\n",
      "added tokens file saved in ./bart_empathetic/checkpoint-22062/added_tokens.json\n",
      "Deleting older checkpoint [bart_empathetic/checkpoint-7354] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./bart_empathetic/checkpoint-22062 (score: 0.7738660573959351).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=22062, training_loss=0.7229934566505757, metrics={'train_runtime': 1232.3637, 'train_samples_per_second': 143.21, 'train_steps_per_second': 17.902, 'total_flos': 1.345131978817536e+16, 'train_loss': 0.7229934566505757, 'epoch': 3.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59c828ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./bart_empathetic_final\n",
      "Configuration saved in ./bart_empathetic_final/config.json\n",
      "Model weights saved in ./bart_empathetic_final/pytorch_model.bin\n",
      "tokenizer config file saved in ./bart_empathetic_final/tokenizer_config.json\n",
      "Special tokens file saved in ./bart_empathetic_final/special_tokens_map.json\n",
      "added tokens file saved in ./bart_empathetic_final/added_tokens.json\n",
      "tokenizer config file saved in ./bart_empathetic_final/tokenizer_config.json\n",
      "Special tokens file saved in ./bart_empathetic_final/special_tokens_map.json\n",
      "added tokens file saved in ./bart_empathetic_final/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./bart_empathetic_final/tokenizer_config.json',\n",
       " './bart_empathetic_final/special_tokens_map.json',\n",
       " './bart_empathetic_final/vocab.json',\n",
       " './bart_empathetic_final/merges.txt',\n",
       " './bart_empathetic_final/added_tokens.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./bart_empathetic_final\")\n",
    "tokenizer.save_pretrained(\"./bart_empathetic_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3dc54-13cd-4569-93a3-5553ff12a8c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading emotion classifier for inference only\n",
    "from transformers import RobertaForSequenceClassification,RobertaTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1a) Load a pretrained emotion detector\n",
    "emo_tokenizer = RobertaTokenizer.from_pretrained(\"./rob-large-emotion-detector_dedupe/\")\n",
    "emo_model     = RobertaForSequenceClassification.from_pretrained(\"./rob-large-emotion-detector_dedupe/\")\n",
    "emo_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883cc2aa-2f21-4f73-a3a8-621204e9b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_emotion(text: str) -> str:\n",
    "    inputs = emo_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    ).to(device)\n",
    "    \n",
    "    logits = emo_model(**inputs).logits\n",
    "    probs  = F.softmax(logits, dim=-1)\n",
    "    idx    = probs.argmax(dim=-1).item()\n",
    "    \n",
    "    return id_to_emotion[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb41c17-1aed-442f-8372-7228d89240af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./Chatbot Training copy/bart_empathetic_final/\"\n",
    "tokenizer_final = BartTokenizer.from_pretrained(model_path)\n",
    "model_final = BartForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a9c451a-8432-4245-be3b-bb9179bed006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tox_tokenizer = AutoTokenizer.from_pretrained(\"sentinet/suicidality\")\n",
    "tox_model = AutoModelForSequenceClassification.from_pretrained(\"sentinet/suicidality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d192919-7fcd-4992-b5ac-bd11447ae3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\n",
    "    'jealous', 'furious', 'disgusted', 'nostalgic', 'impressed', 'faithful',\n",
    "    'caring', 'confident', 'guilty', 'angry', 'disappointed', 'sentimental',\n",
    "    'anxious', 'annoyed', 'embarrassed', 'terrified', 'apprehensive', 'grateful',\n",
    "    'sad', 'afraid', 'ashamed', 'devastated', 'joyful', 'hopeful', 'lonely',\n",
    "    'prepared', 'trusting', 'anticipating', 'excited', 'surprised', 'content', 'proud'\n",
    "]\n",
    "\n",
    "emotion_to_id = {emotion: idx for idx, emotion in enumerate(emotions)}\n",
    "id_to_emotion = {idx: emotion for emotion, idx in emotion_to_id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c75d97-6d8c-49aa-b8a3-6c1a418dd2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Chat function that tracks context and generates a response based on previous conversation\n",
    "def chat(prompt, emotion, conversation_history=None):\n",
    "    if conversation_history is None:\n",
    "        conversation_history = \"\"\n",
    "    \n",
    "    # Formatting the input\n",
    "    input_text = f\"<emotion={emotion}> {conversation_history} [Speaker 0] {prompt}\"\n",
    "    \n",
    "    # Tokenizing the input text\n",
    "    inputs = tokenizer_final(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    # Generate a response using the model\n",
    "    outputs = model_final.generate(\n",
    "        **inputs, \n",
    "        max_length=64, \n",
    "        num_beams=5, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode the output and skip special tokens\n",
    "    response = tokenizer_final.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Adding the prompt and response to the conversation history\n",
    "    conversation_history += f\"[Speaker 0] {prompt} [Speaker 1] {response} \"\n",
    "    \n",
    "    return response, conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "890ddf8c-ae37-4f8c-9faa-a0a9cb802dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  I feel really lonely. What should I do ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm sorry to hear that. What are you going to do?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  I don't know. Can you help me ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm sure you can.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  No I meant can you do something ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm sure you can.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  /exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm sorry to hear that. I hope you feel better soon.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye! Take care!\n"
     ]
    }
   ],
   "source": [
    "# Example conversation loop\n",
    "conversation_history = \"\"\n",
    "while True:\n",
    "    prompt = input(\"You: \")\n",
    "        # Allow the user to exit the chat by typing 'exit'\n",
    "    if prompt.lower() == \"exit\":\n",
    "        print(\"Bot: Goodbye! Take care!\")\n",
    "        break\n",
    "    emotion = detect_emotion(prompt)\n",
    "    response, conversation_history = chat(prompt, emotion, conversation_history)\n",
    "    print(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92726e58",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d834d77d-8519-4e9d-84ed-60a9d0f2d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6821945-b5e1-4929-b183-6cbaef32195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cf58767-f31e-4867-b44f-9c47e2b05666",
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2408d-6886-414b-bf1e-a54bd687a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, tokenizer, test_dataset, data_collator):\n",
    "    dataloader = DataLoader(test_dataset, batch_size=4, collate_fn=data_collator)\n",
    "    model.eval()\n",
    "    # model.to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "                num_beams=2,\n",
    "            )\n",
    "\n",
    "        preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        labels = batch[\"labels\"]\n",
    "    \n",
    "        labels_with_pad = torch.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels_with_pad, skip_special_tokens=True)\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(decoded_labels)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge_score = rouge.compute(predictions=all_preds, references=all_labels, use_stemmer=True)\n",
    "\n",
    "    # BLEU\n",
    "    bleu_score = sacrebleu.compute(predictions=all_preds, references=[[ref] for ref in all_labels])\n",
    "\n",
    "    # BERTScore\n",
    "    bert_score = bertscore.compute(predictions=all_preds, references=all_labels, lang=\"en\")\n",
    "    bertscore_precision = np.mean(bert_score[\"precision\"])\n",
    "    bertscore_recall = np.mean(bert_score[\"recall\"])\n",
    "    bertscore_f1 = np.mean(bert_score[\"f1\"])\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge_score[\"rouge1\"],\n",
    "        \"rouge2\": rouge_score[\"rouge2\"],\n",
    "        \"rougeL\": rouge_score[\"rougeL\"],\n",
    "        \"bleu\": bleu_score[\"score\"],\n",
    "        \"bertscore_precision\": bertscore_precision,\n",
    "        \"bertscore_recall\": bertscore_recall,\n",
    "        \"bertscore_f1\": bertscore_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78f45c65-a43c-4666-a76e-a050128294e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06f3680c-ffdc-4330-b41c-5a4cd2c972df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = load_from_disk(\"./bart_tokenized_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fdeb157-2d5f-4721-bed4-2449cc715e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(50297, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50297, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50297, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50297, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30844d25-4cd9-46dc-8b4a-4941eb3b74f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer_final, model=model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7d2eb67-7c6c-441b-9e49-80a8c09daff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "test_results = test_loop(model_final, tokenizer_final,tokenized_dataset['test'], data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92861755-02ce-48c9-bc4b-fa53cb97d157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(0.2000004994188989),\n",
       " 'rouge2': np.float64(0.05244676667429022),\n",
       " 'rougeL': np.float64(0.17877279791528627),\n",
       " 'bleu': 2.5243624410752825,\n",
       " 'bertscore_precision': np.float64(0.8752496373708752),\n",
       " 'bertscore_recall': np.float64(0.8629908077050754),\n",
       " 'bertscore_f1': np.float64(0.8689322973018515)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34518c3e-dec0-4aca-9af5-3cde5d060765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge 1 score is 20.00004994188989\n",
      "Rouge 2 score is 5.244676667429022\n",
      "Rouge L score is 17.87727979152863\n",
      "BLEU score is 2.5243624410752825\n",
      "Bertscore Precision is 87.52496373708752\n",
      "Bertscore Recall is 86.29908077050754\n",
      "Bertscore F1 is 86.89322973018515\n"
     ]
    }
   ],
   "source": [
    "print(\"Rouge 1 score is\", test_results['rouge1'] * 100)\n",
    "print(\"Rouge 2 score is\", test_results['rouge2'] * 100)\n",
    "print(\"Rouge L score is\", test_results['rougeL'] * 100)\n",
    "print(\"BLEU score is\", test_results['bleu'])\n",
    "print(\"Bertscore Precision is\", test_results['bertscore_precision'] * 100)\n",
    "print(\"Bertscore Recall is\", test_results['bertscore_recall'] * 100)\n",
    "print(\"Bertscore F1 is\", test_results['bertscore_f1'] * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
