{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab495a1",
   "metadata": {},
   "source": [
    "### Model 1: BlenderBot model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e544deb-db5a-4c7e-b168-22ebf3608828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    BlenderbotTokenizer,\n",
    "    BlenderbotForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer\n",
    ")\n",
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33c9c7b-ed1f-4bbf-97ae-9904cbf9eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e66c8e9-1dc2-4ae1-a88e-200a7d065f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c007ad-f00d-41af-ab2e-044901f4e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, tokenizer, test_dataset, data_collator):\n",
    "    dataloader = DataLoader(test_dataset, batch_size=4, collate_fn=data_collator)\n",
    "    model.eval()\n",
    "    # model.to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "                num_beams=2,\n",
    "            )\n",
    "\n",
    "        preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_with_pad = torch.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels_with_pad, skip_special_tokens=True)\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(decoded_labels)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge_score = rouge.compute(predictions=all_preds, references=all_labels, use_stemmer=True)\n",
    "\n",
    "    # BLEU\n",
    "    bleu_score = sacrebleu.compute(predictions=all_preds, references=[[ref] for ref in all_labels])\n",
    "\n",
    "    # BERTScore\n",
    "    bert_score = bertscore.compute(predictions=all_preds, references=all_labels, lang=\"en\")\n",
    "    bertscore_precision = np.mean(bert_score[\"precision\"])\n",
    "    bertscore_recall = np.mean(bert_score[\"recall\"])\n",
    "    bertscore_f1 = np.mean(bert_score[\"f1\"])\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge_score[\"rouge1\"],\n",
    "        \"rouge2\": rouge_score[\"rouge2\"],\n",
    "        \"rougeL\": rouge_score[\"rougeL\"],\n",
    "        \"bleu\": bleu_score[\"score\"],\n",
    "        \"bertscore_precision\": bertscore_precision,\n",
    "        \"bertscore_recall\": bertscore_recall,\n",
    "        \"bertscore_f1\": bertscore_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e41522-718c-437f-982c-0e5c42ae0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"facebook/empathetic_dialogues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72fcd628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d93cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = load_from_disk(\"./Chatbot Training/blender_tokenized_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764baf36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"./Chatbot Training/blender_empathetic_final/\"\n",
    "tokenizer_final = BlenderbotTokenizer.from_pretrained(model_path)\n",
    "model_final = BlenderbotForConditionalGeneration.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf65da3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "670d80d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlenderbotForConditionalGeneration(\n",
       "  (model): BlenderbotModel(\n",
       "    (shared): BlenderbotScaledWordEmbedding(8041, 1280, padding_idx=0)\n",
       "    (encoder): BlenderbotEncoder(\n",
       "      (embed_tokens): BlenderbotScaledWordEmbedding(8041, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BlenderbotDecoder(\n",
       "      (embed_tokens): BlenderbotScaledWordEmbedding(8041, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=8041, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ccc50c0-7556-4c45-85dd-1bf1f7041bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer_final, model=model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad8095c8-ff0f-434b-99a5-f5a1147264d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "test_results = test_loop(model_final, tokenizer_final,tokenized_dataset['test'], data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5ffee91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': np.float64(0.1970258452150462),\n",
       " 'rouge2': np.float64(0.048995485008865955),\n",
       " 'rougeL': np.float64(0.1729539956933947),\n",
       " 'bleu': 2.6440061779484996,\n",
       " 'bertscore_precision': np.float64(0.8707038615839667),\n",
       " 'bertscore_recall': np.float64(0.8642908634422989),\n",
       " 'bertscore_f1': np.float64(0.8673355983103836)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2db1d35-16d0-40a8-8b4c-04b30b1bb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge 1 score is 19.702584521504622\n",
      "Rouge 2 score is 4.8995485008865955\n",
      "Rouge L score is 17.29539956933947\n",
      "BLEU score is 2.6440061779484996\n",
      "Bertscore Precision is 87.07038615839667\n",
      "Bertscore Recall is 86.42908634422989\n",
      "Bertscore F1 is 86.73355983103836\n"
     ]
    }
   ],
   "source": [
    "print(\"Rouge 1 score is\", test_results['rouge1'] * 100)\n",
    "print(\"Rouge 2 score is\", test_results['rouge2'] * 100)\n",
    "print(\"Rouge L score is\", test_results['rougeL'] * 100)\n",
    "print(\"BLEU score is\", test_results['bleu'])\n",
    "print(\"Bertscore Precision is\", test_results['bertscore_precision'] * 100)\n",
    "print(\"Bertscore Recall is\", test_results['bertscore_recall'] * 100)\n",
    "print(\"Bertscore F1 is\", test_results['bertscore_f1'] * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
